import streamlit as st
import cv2
import os
import tempfile
import base64
import json
import pandas as pd
from moviepy.editor import VideoFileClip
from scenedetect import VideoManager, SceneManager
from scenedetect.detectors import ContentDetector
from openai import OpenAI
import numpy as np
import gspread
from google.oauth2.service_account import Credentials
import time  # é·ç§»æ¼”å‡ºç”¨ã«è¿½åŠ 

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(
    page_title="ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼",
    page_icon="ğŸ¬",
    layout="wide"
)

# --- å®šæ•°ãƒ»è¨­å®š ---
SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive"
]

# â˜…ã‚³ã‚¹ãƒˆç®¡ç†ã®ãŸã‚ã®åˆ¶é™è¨­å®šâ˜…
MAX_VIDEO_DURATION = 60  # æœ€å¤§å‹•ç”»æ™‚é–“ï¼ˆç§’ï¼‰
MAX_ANALYZE_SCENES = 30  # è§£æã™ã‚‹æœ€å¤§ã‚·ãƒ¼ãƒ³æ•°
DEFAULT_MIN_SCENE_LEN = 30 # æœ€å°ã‚·ãƒ¼ãƒ³é•·ï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼‰ã€‚30ãƒ•ãƒ¬ãƒ¼ãƒ â‰’1ç§’ã€‚

# --- é–¢æ•°å®šç¾©: Google Sheetsé€£æº ---
def get_gspread_client():
    """Secretsã‹ã‚‰èªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã€gspreadã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’è¿”ã™"""
    try:
        if "gcp_service_account" not in st.secrets:
            # é–‹ç™ºç’°å¢ƒãªã©ã§SecretsãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆã¾ãŸã¯ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºï¼‰
            # st.error("Secretsã«Googleèªè¨¼æƒ…å ±ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return None
            
        creds_dict = dict(st.secrets["gcp_service_account"])
        
        if "\\n" in creds_dict["private_key"]:
             creds_dict["private_key"] = creds_dict["private_key"].replace("\\n", "\n")
             
        creds = Credentials.from_service_account_info(creds_dict, scopes=SCOPES)
        client = gspread.authorize(creds)
        return client
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return None

def check_login(username, password):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ç…§åˆã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã‚’è¿”ã™"""
    client = get_gspread_client()
    if not client:
        # DBæ¥ç¶šã§ããªã„å ´åˆã¯ç·Šæ€¥æªç½®ã¨ã—ã¦ãƒ‡ãƒ¢ãƒ­ã‚°ã‚¤ãƒ³ã‚’é€šã™ã‹ã€ã‚¨ãƒ©ãƒ¼ã«ã™ã‚‹
        # ã“ã“ã§ã¯ã‚¨ãƒ©ãƒ¼ã¨ã—ã¦è¿”ã™
        return None

    try:
        sheet_url = st.secrets["SPREADSHEET_URL"]
        sheet = client.open_by_url(sheet_url).sheet1
        records = sheet.get_all_records()
        
        for i, record in enumerate(records):
            if str(record['username']) == username and str(record['password']) == password:
                record['row_index'] = i + 2
                return record
        return None
    except Exception as e:
        st.error(f"ãƒ­ã‚°ã‚¤ãƒ³å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def update_usage(row_index, current_usage):
    """ä½¿ç”¨å›æ•°ã‚’+1ã™ã‚‹"""
    client = get_gspread_client()
    if not client:
        return False
    
    try:
        sheet_url = st.secrets["SPREADSHEET_URL"]
        sheet = client.open_by_url(sheet_url).sheet1
        header = sheet.row_values(1)
        try:
            col_index = header.index("usage") + 1
        except ValueError:
            st.error("DBã‚¨ãƒ©ãƒ¼: usageåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
            
        sheet.update_cell(row_index, col_index, current_usage + 1)
        return True
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        return False

# --- èªè¨¼æ©Ÿèƒ½ (ãƒ­ã‚°ã‚¤ãƒ³ç”»é¢) ---
def login_screen():
    st.title("ğŸ¬ ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼")
    
    # ãƒ‡ã‚¶ã‚¤ãƒ³èª¿æ•´ï¼šã‚«ãƒ©ãƒ ã‚’ä½¿ã£ã¦ä¸­å¤®å¯„ã›é¢¨ã«è¦‹ã›ã‚‹
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        with st.form("login_form"):
            st.subheader("ä¼šå“¡ãƒ­ã‚°ã‚¤ãƒ³")
            st.caption("ã‚¹ã‚¯ãƒ¼ãƒ«ã‹ã‚‰ç™ºè¡Œã•ã‚ŒãŸIDã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
            
            username = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼ID", placeholder="ä¾‹: user01")
            password = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
            
            # å°‘ã—ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç©ºã‘ã‚‹
            st.write("") 
            submit = st.form_submit_button("ãƒ­ã‚°ã‚¤ãƒ³", use_container_width=True)
            
            if submit:
                if not username or not password:
                    st.warning("âš ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼IDã¨ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                else:
                    with st.spinner("ç¢ºèªä¸­..."):
                        user_info = check_login(username, password)
                    
                    if user_info:
                        st.session_state["user"] = user_info
                        st.success("èªè¨¼æˆåŠŸï¼ã‚¢ãƒ—ãƒªã‚’èµ·å‹•ã—ã¾ã™...")
                        time.sleep(1) # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¾ã›ã‚‹ãŸã‚ã®çŸ­ã„ã‚¦ã‚§ã‚¤ãƒˆ
                        st.rerun()
                    else:
                        # ã“ã“ã§èµ¤å­—(error)ã§ã¯ãªãé»„è‰²(warning)ã‚’ä½¿ç”¨
                        st.warning("âš ï¸ ãƒ­ã‚°ã‚¤ãƒ³ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\n\nIDã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚å…¥åŠ›ãƒŸã‚¹ãŒãªã„ã‹ï¼ˆå¤§æ–‡å­—ãƒ»å°æ–‡å­—ãªã©ï¼‰ã‚’ã”ç¢ºèªãã ã•ã„ã€‚")

if "user" in st.session_state and st.sidebar.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):
    del st.session_state["user"]
    st.rerun()

if "user" not in st.session_state:
    login_screen()
    st.stop()

# ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã®å–å¾—
user = st.session_state["user"]
limit = int(user['limit'])
usage = int(user['usage'])
remaining = limit - usage

# --- ã‚¢ãƒ—ãƒªç”»é¢ ---
st.sidebar.markdown(f"**ãƒ­ã‚°ã‚¤ãƒ³ä¸­:** {user['username']}")
st.sidebar.metric("ä»Šæœˆã®æ®‹ã‚Šå›æ•°", f"{remaining} / {limit}")
st.sidebar.progress(usage / limit if limit > 0 else 0)

if remaining <= 0:
    st.error("ä»Šæœˆã®ä¸Šé™å›æ•°ã«é”ã—ã¾ã—ãŸã€‚ãƒ—ãƒ©ãƒ³ã®ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚’ã”æ¤œè¨ãã ã•ã„ã€‚")
    st.stop()

# ==========================================
# è§£ææ©Ÿèƒ½ (ãƒ¡ã‚¤ãƒ³)
# ==========================================

st.title("ğŸ¬ ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼")
st.markdown("""
Instagram Reelsã‚„TikTokå‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€ã‚·ãƒ¼ãƒ³ã”ã¨ã®æ§‹æˆè¦ç´ ï¼ˆè¦–è¦šæƒ…å ±ã€ãƒ†ãƒ­ãƒƒãƒ—ã€éŸ³å£°ã€æ¼”å‡ºï¼‰ã‚’è‡ªå‹•åˆ†æã—ã¾ã™ã€‚
â€»è§£æå¯¾è±¡ã¯1åˆ†ä»¥å†…ã®å‹•ç”»ã«é™ã‚Šã¾ã™ã€‚
""")

try:
    api_key = st.secrets["OPENAI_API_KEY"]
except:
    api_key = os.getenv("OPENAI_API_KEY")

if not api_key:
    st.error("ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: API Keyè¨­å®šä¸å‚™")
    st.stop()

client = OpenAI(api_key=api_key)

def detect_scenes(video_path, threshold=27.0, min_scene_len=15):
    video_manager = VideoManager([video_path])
    scene_manager = SceneManager()
    scene_manager.add_detector(ContentDetector(threshold=threshold, min_scene_len=min_scene_len))
    video_manager.set_downscale_factor()
    video_manager.start()
    scene_manager.detect_scenes(frame_source=video_manager)
    scene_list = scene_manager.get_scene_list(video_manager.get_base_timecode())
    return scene_list

def extract_frame_as_base64(video_path, time_sec):
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_no = int(time_sec * fps)
    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_no)
    ret, frame = cap.read()
    cap.release()
    if not ret: return None, None
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    _, buffer = cv2.imencode('.jpg', cv2.cvtColor(frame_rgb, cv2.COLOR_RGB2BGR))
    base64_image = base64.b64encode(buffer).decode('utf-8')
    return frame_rgb, base64_image

def transcribe_audio(audio_path):
    try:
        with open(audio_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1", file=audio_file, response_format="verbose_json"
            )
        return transcript
    except Exception as e:
        return None

def analyze_image_with_gpt4o(base64_image, scene_no):
    """
    ã‚·ãƒ¼ãƒ³ç•ªå·ã‚’å—ã‘å–ã‚Šã€å†’é ­(Scene 1, 2)ã®å ´åˆã¯ãƒ•ãƒƒã‚¯è¦ç´ ã‚’é‡ç‚¹çš„ã«åˆ†æã•ã›ã‚‹
    """
    
    # å†’é ­ã‚·ãƒ¼ãƒ³ã‹ã©ã†ã‹ã®åˆ¤å®šã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    context_instruction = ""
    if scene_no <= 2:
        context_instruction = "ã“ã®ç”»åƒã¯å‹•ç”»ã®å†’é ­ï¼ˆScene 1ã¾ãŸã¯2ï¼‰ã§ã™ã€‚è¦–è´è€…ã®æŒ‡ã‚’æ­¢ã‚ã‚‹ãŸã‚ã®ã€ãƒ•ãƒƒã‚¯è¦ç´ ï¼ˆãƒã‚ºã‚‹è¦ç´ ï¼‰ã€ã‚’é‡ç‚¹çš„ã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"
    
    system_prompt = f"""
    ã‚ãªãŸã¯SNSã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ï¼ˆTikTok/Reelsï¼‰ã®ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°å°‚é–€å®¶ã§ã™ã€‚
    æ¸¡ã•ã‚ŒãŸç”»åƒï¼ˆ1ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰ã‚’åˆ†æã—ã€ä»¥ä¸‹ã®JSONå½¢å¼ã®ã¿ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    
    {context_instruction}

    å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
    {{
      "visual_content": "ç”»é¢ã®çŠ¶æ³èª¬æ˜ï¼ˆèª°ãŒã€ã©ã“ã§ã€ä½•ã‚’ã—ã¦ã„ã‚‹ã‹ï¼‰",
      "on_screen_text": "ç”»é¢ã«è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹æ–‡å­—å…¨ã¦",
      "vibes": "é›°å›²æ°—ã‚„æ¼”å‡ºã®æ„å›³",
      "psychological_effects": "ãƒ†ã‚­ã‚¹ãƒˆã‚„è¦–è¦šæƒ…å ±ã«å«ã¾ã‚Œã‚‹ã€å¿ƒç†åŠ¹æœã€ã‚’è¨€èªåŒ–ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šãƒãƒ³ãƒ‰ãƒ¯ã‚´ãƒ³åŠ¹æœã€ã‚«ãƒªã‚®ãƒ¥ãƒ©åŠ¹æœã€ç¤¾ä¼šçš„è¨¼æ˜ã€å¸Œå°‘æ€§ã€æ¨©å¨æ€§ãªã©ï¼‰ã€‚ç‰¹ã«ãªã‘ã‚Œã°ã€ãªã—ã€ã¨ã—ã¦ãã ã•ã„ã€‚",
      "hook_factor": "ï¼ˆã‚·ãƒ¼ãƒ³1, 2ã®å ´åˆã®ã¿è¨˜è¿°ã€ãã‚Œä»¥å¤–ã¯ã€-ã€ï¼‰å†’é ­3ç§’ã®ãƒ•ãƒƒã‚¯ã¨ã—ã¦ã€ãªãœè¦–è´è€…ãŒæŒ‡ã‚’æ­¢ã‚ã‚‹ã®ã‹ï¼Ÿãƒã‚ºã‚‹è¦å› ã¨ãªã‚‹ã€æ„å¤–æ€§ã€ã€å…±æ„Ÿã€ã€é•å’Œæ„Ÿã€ã€ç–‘å•ã€ãªã©ã‚’å…·ä½“çš„ã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"
    }}
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": [
                    {"type": "text", "text": f"ã“ã‚Œã¯Scene {scene_no}ã§ã™ã€‚è©³ç´°ã«åˆ†æã—ã¦ãã ã•ã„ã€‚"},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                ]}
            ],
            response_format={"type": "json_object"},
            max_tokens=600
        )
        return json.loads(response.choices[0].message.content)
    except:
        return {
            "visual_content": "Error", 
            "on_screen_text": "Error", 
            "vibes": "Error",
            "psychological_effects": "Error",
            "hook_factor": "Error"
        }

def generate_overall_summary(scene_results):
    if not scene_results: return ""
    combined_text = "\n".join([
        f"Scene {item['Scene No']}: {item['Visual Description']} (Psychology: {item['Psychological Effects']}, Hook: {item['Hook Factor']})"
        for item in scene_results
    ])
    system_prompt = "ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»ã®ã‚·ãƒ¼ãƒ³è©³ç´°ã‹ã‚‰ã€å‹•ç”»å…¨ä½“ã®æ¦‚è¦ã‚’3-4è¡Œã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚ã¾ãŸã€å…¨ä½“ã‚’é€šã—ã¦ä½¿ã‚ã‚Œã¦ã„ã‚‹ä¸»è¦ãªå¿ƒç†ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ãŒã‚ã‚Œã°ä¸€è¨€ä»˜ã‘åŠ ãˆã¦ãã ã•ã„ã€‚"
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": combined_text}],
            max_tokens=400
        )
        return response.choices[0].message.content
    except: return "è¦ç´„ã‚¨ãƒ©ãƒ¼"

# --- UIå®Ÿè£… ---

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.subheader("è§£æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
threshold = st.sidebar.slider("ã‚·ãƒ¼ãƒ³æ¤œå‡ºæ„Ÿåº¦", 10.0, 50.0, 27.0)
min_scene_len = st.sidebar.slider("æœ€å°ã‚·ãƒ¼ãƒ³é•·", 10, 60, DEFAULT_MIN_SCENE_LEN)

uploaded_file = st.file_uploader("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (mp4, mov)", type=["mp4", "mov"])

if uploaded_file is not None:
    tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
    tfile.write(uploaded_file.read())
    video_path = tfile.name
    tfile.close()

    # å‹•ç”»æƒ…å ±ã®å–å¾—
    try:
        video_clip = VideoFileClip(video_path)
        video_duration = video_clip.duration
        
        # â˜…1. å‹•ç”»ã®é•·ã•ãƒã‚§ãƒƒã‚¯
        if video_duration > MAX_VIDEO_DURATION:
            st.error(f"å‹•ç”»ãŒé•·ã™ãã¾ã™ï¼ˆ{video_duration:.1f}ç§’ï¼‰ã€‚{MAX_VIDEO_DURATION}ç§’ä»¥å†…ã®å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            try:
                video_clip.close()
                os.remove(video_path)
            except: pass
            st.stop()
            
        col_spacer1, col_video, col_spacer2 = st.columns([1, 2, 1])
        with col_video:
            st.video(video_path)

        if st.button("ğŸš€ å‹•ç”»ã‚’åˆ†æé–‹å§‹"):
            if remaining <= 0:
                st.error("ä¸Šé™å›æ•°ã«é”ã—ã¦ã„ã‚‹ãŸã‚å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
            else:
                status_text = st.empty()
                progress_bar = st.progress(0)
                
                try:
                    # 1. éŸ³å£°å‡¦ç†
                    status_text.info("ğŸ”Š éŸ³å£°ã‚’è§£æä¸­...")
                    audio_path = os.path.join(tempfile.gettempdir(), "temp_audio.mp3")
                    transcript_text = "éŸ³å£°ãªã—"
                    transcript_segments = []
                    if video_clip.audio:
                        video_clip.audio.write_audiofile(audio_path, verbose=False, logger=None)
                        tr_data = transcribe_audio(audio_path)
                        if tr_data:
                            transcript_text = tr_data.text
                            transcript_segments = getattr(tr_data, 'segments', [])
                        if os.path.exists(audio_path): os.remove(audio_path)
                    progress_bar.progress(20)

                    # 2. ã‚·ãƒ¼ãƒ³æ¤œå‡º
                    status_text.info("âœ‚ï¸ ã‚·ãƒ¼ãƒ³æ¤œå‡ºä¸­...")
                    scenes = detect_scenes(video_path, threshold, min_scene_len)
                    if not scenes:
                        scene_data_list = [{'start': 0.0, 'end': video_duration}]
                    else:
                        scene_data_list = [{'start': s[0].get_seconds(), 'end': s[1].get_seconds()} for s in scenes]
                    
                    # â˜…2. ã‚·ãƒ¼ãƒ³æ•°åˆ¶é™ï¼ˆã‚³ã‚¹ãƒˆä¿è­·ï¼‰
                    if len(scene_data_list) > MAX_ANALYZE_SCENES:
                        st.warning(f"ã‚·ãƒ¼ãƒ³æ•°ãŒå¤šã™ãã‚‹ãŸã‚ï¼ˆ{len(scene_data_list)}å€‹ï¼‰ã€å…ˆé ­ã®{MAX_ANALYZE_SCENES}ã‚·ãƒ¼ãƒ³ã®ã¿è§£æã—ã¾ã™ã€‚")
                        scene_data_list = scene_data_list[:MAX_ANALYZE_SCENES]

                    progress_bar.progress(40)

                    # 3. GPTè§£æ
                    status_text.info(f"ğŸ‘ï¸ GPT-4oã§{len(scene_data_list)}ã‚·ãƒ¼ãƒ³ã‚’è§£æä¸­...")
                    results = []
                    total_scenes = len(scene_data_list)
                    for i, scene in enumerate(scene_data_list):
                        start_sec = scene['start']
                        end_sec = scene['end']
                        mid_sec = start_sec + (end_sec - start_sec) / 2
                        
                        img_rgb, base64_img = extract_frame_as_base64(video_path, mid_sec)
                        if base64_img:
                            # ã‚·ãƒ¼ãƒ³ç•ªå·ã‚’æ¸¡ã—ã¦è§£æ
                            analysis = analyze_image_with_gpt4o(base64_img, i + 1)
                            
                            scene_audio = ""
                            for seg in transcript_segments:
                                seg_start = getattr(seg, 'start', seg.get('start') if isinstance(seg, dict) else 0)
                                seg_text = getattr(seg, 'text', seg.get('text') if isinstance(seg, dict) else "")
                                if start_sec <= seg_start < end_sec:
                                    scene_audio += seg_text + " "
                            
                            results.append({
                                "Scene No": i + 1,
                                "Start Time": f"{start_sec:.2f}s",
                                "End Time": f"{end_sec:.2f}s",
                                "Duration": f"{end_sec-start_sec:.2f}s",
                                "Visual Description": analysis.get("visual_content", ""),
                                "On-Screen Text": analysis.get("on_screen_text", ""),
                                "Vibes": analysis.get("vibes", ""),
                                "Psychological Effects": analysis.get("psychological_effects", ""),
                                "Hook Factor": analysis.get("hook_factor", ""),
                                "Audio Transcript": scene_audio.strip(),
                                "Image Data": img_rgb
                            })
                        progress_bar.progress(40 + int((i + 1) / total_scenes * 60))

                    # 4. è¦ç´„ç”Ÿæˆ
                    status_text.info("ğŸ“ ã‚µãƒãƒªãƒ¼ç”Ÿæˆä¸­...")
                    overall_summary = generate_overall_summary(results)
                    progress_bar.progress(100)
                    status_text.success("âœ… è§£æå®Œäº†ï¼")
                    
                    # DBæ›´æ–°
                    new_usage = usage + 1
                    if update_usage(user['row_index'], new_usage):
                        st.session_state["user"]["usage"] = new_usage
                        st.toast(f"æ®‹ã‚Šå›æ•°: {limit - new_usage}")
                    else:
                        st.warning("ä½¿ç”¨å›æ•°ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€è§£æçµæœã¯è¡¨ç¤ºã—ã¾ã™ã€‚")

                    # çµæœè¡¨ç¤º
                    st.divider()
                    st.subheader("ğŸ“Š åˆ†æãƒ¬ãƒãƒ¼ãƒˆ")
                    st.markdown("### ğŸ“ å…¨ä½“æ¦‚è¦")
                    c1, c2, c3 = st.columns(3)
                    c1.metric("ã‚·ãƒ¼ãƒ³æ•°", len(results))
                    c2.metric("ç§’æ•°", f"{video_duration:.1f}s")
                    st.markdown(f"**å†…å®¹:**\n{overall_summary}")
                    st.divider()
                    st.markdown("### ğŸï¸ ã‚·ãƒ¼ãƒ³åˆ¥è©³ç´°")

                    export_data = []
                    for item in results:
                        st.markdown(f"#### Scene {item['Scene No']} ({item['Start Time']} - {item['End Time']})")
                        
                        # å†’é ­ã‚·ãƒ¼ãƒ³ã®å ´åˆã€ãƒ•ãƒƒã‚¯è¦ç´ ã‚’å¼·èª¿è¡¨ç¤º
                        if item["Hook Factor"] and item["Hook Factor"] != "-" and item["Hook Factor"] != "ãªã—":
                            st.info(f"**ğŸ£ å†’é ­ãƒ•ãƒƒã‚¯è¦ç´  (ãƒã‚ºè¦å› ):** {item['Hook Factor']}")

                        c1, c2 = st.columns([1, 2])
                        with c1:
                            if item["Image Data"] is not None:
                                st.image(item["Image Data"], use_container_width=True)
                        with c2:
                            st.markdown(f"**ğŸ§  å¿ƒç†åŠ¹æœ:** {item['Psychological Effects']}")
                            st.markdown(f"**ğŸ–¼ï¸ è¦–è¦šæƒ…å ±:** {item['Visual Description']}")
                            st.markdown(f"**ğŸ“ ãƒ†ãƒ­ãƒƒãƒ—:** {item['On-Screen Text']}")
                            st.markdown(f"**ğŸ™ï¸ éŸ³å£°:** {item['Audio Transcript']}")
                            st.markdown(f"**âœ¨ Vibes:** {item['Vibes']}")
                        st.divider()
                        export_item = item.copy()
                        if "Image Data" in export_item: del export_item["Image Data"]
                        export_data.append(export_item)

                    df = pd.DataFrame(export_data)
                    csv = df.to_csv(index=False).encode('utf-8-sig')
                    st.download_button("ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv, "analysis.csv", "text/csv")
                    st.download_button("ğŸ“¥ Markdownãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", df.to_markdown(index=False), "analysis.md", "text/markdown")

                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                finally:
                    if 'video_clip' in locals(): video_clip.close()
                    if os.path.exists(video_path): os.remove(video_path)

    except Exception as e:
        st.error(f"å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
